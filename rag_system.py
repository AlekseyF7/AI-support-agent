""" 
Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° RAG (Retrieval-Augmented Generation) Ğ½Ğ° Ğ±Ğ°Ğ·Ğµ ChromaDB Ğ¸ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ².
ĞĞ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ¿Ğ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ğ±Ğ°Ğ·Ğµ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ±ĞµĞ· Ğ·Ğ°Ñ‚Ñ€Ğ°Ñ‚ Ğ½Ğ° API.
"""
import os
import logging
import asyncio
from typing import List, Optional, Any

import chromadb
from chromadb.api.types import Documents, EmbeddingFunction, Embeddings
from sentence_transformers import SentenceTransformer

from config import settings

logger = logging.getLogger(__name__)

class LocalEmbeddingFunction(EmbeddingFunction):
    """
    ĞĞ´Ğ°Ğ¿Ñ‚ĞµÑ€ Ğ´Ğ»Ñ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ² Ñ‡ĞµÑ€ĞµĞ· SentenceTransformer.
    Ğ¡Ğ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼ Ñ Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ»Ğ¾Ğ¼ EmbeddingFunction ChromaDB.
    """
    
    def __init__(self, model_name: Optional[str] = None):
        """
        Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. 
        """
        self.model_name = model_name or settings.EMBEDDING_MODEL_NAME
        logger.info(f"ğŸ§  Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ²: {self.model_name}")
        try:
            self.model = SentenceTransformer(self.model_name, trust_remote_code=True)
            logger.info("âœ… ĞœĞ¾Ğ´ĞµĞ»ÑŒ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ² ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°.")
        except Exception as e:
            logger.error(f"âŒ Ğ¤Ğ°Ñ‚Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: {e}")
            raise

    def __call__(self, input: Documents) -> Embeddings:
        """
        ĞœĞµÑ‚Ğ¾Ğ´ Ğ´Ğ»Ñ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ñ ChromaDB API. 
        ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¿Ñ€ĞµÑ„Ğ¸ĞºÑ 'passage: ' Ğ´Ğ»Ñ Ğ¸Ğ½Ğ´ĞµĞºÑĞ¸Ñ€ÑƒĞµĞ¼Ñ‹Ñ… Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ².
        """
        # ĞœĞ¾Ğ´ĞµĞ»Ğ¸ instruct Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‚ Ğ¿Ñ€ĞµÑ„Ğ¸ĞºÑĞ¾Ğ²: passage Ğ´Ğ»Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ², query Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ°
        prefixed_texts = [f"passage: {t}" if not t.startswith("query:") else t for t in input]
        embeddings = self.model.encode(prefixed_texts)
        return embeddings.tolist()

class RAGSystem:
    """
    Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ¿Ğ¾ Ğ±Ğ°Ğ·Ğµ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ ÑĞ»ÑƒĞ¶Ğ±Ñ‹ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¸.
    """
    
    def __init__(self, embedding_function: Any = None):
        """
        Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ RAG ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹. 
        
        Args:
            embedding_function: Ğ­ĞºĞ·ĞµĞ¼Ğ¿Ğ»ÑÑ€ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ². Ğ•ÑĞ»Ğ¸ None, ÑĞ¾Ğ·Ğ´Ğ°ĞµÑ‚ÑÑ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ°Ñ.
        """
        self.db_path = settings.CHROMA_DB_PATH
        self.embedding_function = embedding_function or LocalEmbeddingFunction()
        
        # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ChromaDB
        self.client = chromadb.PersistentClient(path=self.db_path)
        self.collection = self.client.get_or_create_collection(
            name="support_knowledge_base_local",
            embedding_function=self.embedding_function,
            metadata={"hnsw:space": "l2"} # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ L2 Ğ´Ğ¸ÑÑ‚Ğ°Ğ½Ñ†Ğ¸Ñ
        )

    async def get_context_for_query(self, query: str, max_results: int = 3, threshold: float = 0.85) -> str:
        """
        ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾ Ğ¸Ñ‰ĞµÑ‚ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½ÑƒÑ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑƒ.
        
        Args:
            query: Ğ¢ĞµĞºÑÑ‚ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ğ¾Ñ‚ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ.
            max_results: ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ².
            threshold: ĞŸĞ¾Ñ€Ğ¾Ğ³ ÑÑ…Ğ¾Ğ¶ĞµÑÑ‚Ğ¸ (0.0 - 1.0), Ğ³Ğ´Ğµ 1.0 - Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ.
            
        Returns:
            ĞšĞ¾Ğ½ĞºĞ°Ñ‚ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ ÑÑ‚Ñ€Ğ¾ĞºĞ° Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°.
        """
        loop = asyncio.get_running_loop()
        return await loop.run_in_executor(None, self._get_context_sync, query, max_results, threshold)

    def _get_context_sync(self, query: str, max_results: int, threshold: float) -> str:
        """Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ğº ChromaDB."""
        try:
            # Ğ”Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ¿Ñ€ĞµÑ„Ğ¸ĞºÑ 'query: '
            prefixed_query = f"query: {query}"
            
            results = self.collection.query(
                query_texts=[prefixed_query],
                n_results=max_results
            )
            
            if not results['documents'] or not results['documents'][0]:
                return ""
            
            # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ Ğ¿Ğ¾Ñ€Ğ¾Ğ³Ñƒ ÑÑ…Ğ¾Ğ¶ĞµÑÑ‚Ğ¸
            valid_docs = []
            for doc, dist in zip(results['documents'][0], results['distances'][0]):
                # Ğ”Ğ»Ñ L2: Ğ¼ĞµĞ½ÑŒÑˆĞ°Ñ Ğ´Ğ¸ÑÑ‚Ğ°Ğ½Ñ†Ğ¸Ñ = Ğ±Ğ¾Ğ»ÑŒÑˆĞµĞµ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾. 
                # ĞšĞ¾ÑĞ²ĞµĞ½Ğ½Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ°: 1 - (dist/2) (Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ Ğ´Ğ»Ñ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¾Ğ²)
                similarity = 1.0 / (1.0 + dist)
                if similarity >= threshold:
                    valid_docs.append(doc)
            
            if not valid_docs:
                logger.debug(f"ğŸ” ĞĞµÑ‚ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ²Ñ‹ÑˆĞµ Ğ¿Ğ¾Ñ€Ğ¾Ğ³Ğ° {threshold} (Ğ»ÑƒÑ‡ÑˆĞ¸Ğ¹ match similarity: {1.0/(1.0+results['distances'][0][0]):.4f})")
                return ""
                
            return "\n---\n".join(valid_docs)
        except Exception as e:
            logger.error(f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° RAG Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°: {e}")
            return ""

    @property
    def chroma_client(self):
        """Ğ”Ğ¾ÑÑ‚ÑƒĞ¿ Ğº JSON ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ñƒ Chroma Ğ´Ğ»Ñ ÑÑĞºĞ°Ğ»Ğ°Ñ†Ğ¸Ğ¸."""
        return self.client

class MockRAGSystem:
    """Ğ—Ğ°Ğ³Ğ»ÑƒÑˆĞºĞ° Ğ´Ğ»Ñ RAG, ĞµÑĞ»Ğ¸ Ğ±Ğ°Ğ·Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ°."""
    async def get_context_for_query(self, query: str, **kwargs) -> str:
        return ""
