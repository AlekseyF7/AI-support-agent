"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π (ChromaDB)
"""

import json
import hashlib
import logging
from pathlib import Path

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)-8s | %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger("LoadSberData")


def load_json_to_rag(json_path: str = "sber_data.json"):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON —Ñ–∞–π–ª–∞ –≤ ChromaDB
    
    Args:
        json_path: –ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏
    """
    from rag_system import RAGSystem
    
    # –ß–∏—Ç–∞–µ–º JSON
    json_file = Path(json_path)
    if not json_file.exists():
        logger.error(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {json_path}")
        return
    
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    logger.info(f"üìÇ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} –∑–∞–ø–∏—Å–µ–π –∏–∑ {json_path}")
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∑–∞–ø–∏—Å–∏
    valid_data = []
    for item in data:
        title = item.get("title", "").strip()
        content = item.get("content", "").strip()
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–ø–∏—Å–∏ —Å –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
        if len(content) < 20:
            continue
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
        if title == content:
            continue
        
        valid_data.append(item)
    
    logger.info(f"‚úÖ –í–∞–ª–∏–¥–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π: {len(valid_data)}")
    
    if not valid_data:
        logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏")
        return
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º RAG —Å–∏—Å—Ç–µ–º—É
    logger.info("üß† –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–∏—Å—Ç–µ–º—ã...")
    rag = RAGSystem()
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è ChromaDB
    documents = []
    metadatas = []
    ids = []
    
    for item in valid_data:
        title = item.get("title", "")
        content = item.get("content", "")
        url = item.get("url", "")
        category = item.get("category", "general")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞
        full_text = f"{title}\n\n{content}"
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID
        doc_id = hashlib.md5(f"{title}:{url}".encode()).hexdigest()
        
        documents.append(full_text)
        metadatas.append({
            "question": title,
            "source": url,
            "category": category
        })
        ids.append(doc_id)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ ChromaDB
    logger.info(f"üíæ –ó–∞–≥—Ä—É–∑–∫–∞ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ ChromaDB...")
    
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º upsert –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π
        rag.collection.upsert(
            documents=documents,
            metadatas=metadatas,
            ids=ids
        )
        
        total_count = rag.collection.count()
        logger.info(f"‚ú® –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ! –í—Å–µ–≥–æ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π: {total_count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        logger.info("\nüìã –ü—Ä–∏–º–µ—Ä—ã –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤:")
        for i, item in enumerate(valid_data[:5], 1):
            logger.info(f"   {i}. {item['title'][:70]}...")
        
        if len(valid_data) > 5:
            logger.info(f"   ... –∏ –µ—â—ë {len(valid_data) - 5} –∑–∞–ø–∏—Å–µ–π")
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        raise


def test_search(query: str = "–ö–∞–∫ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ä—Ç—É?"):
    """–¢–µ—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π"""
    import asyncio
    from rag_system import RAGSystem
    
    logger.info(f"\nüîç –¢–µ—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫: '{query}'")
    
    rag = RAGSystem()
    
    async def search():
        result = await rag.get_context_for_query(query, max_results=3, threshold=0.3)
        return result
    
    result = asyncio.run(search())
    
    if result:
        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ:\n{result[:500]}...")
    else:
        logger.info("‚ùå –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π")
    parser.add_argument(
        '--file', '-f',
        type=str,
        default='sber_data.json',
        help='–ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: sber_data.json)'
    )
    parser.add_argument(
        '--test', '-t',
        action='store_true',
        help='–í—ã–ø–æ–ª–Ω–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏'
    )
    parser.add_argument(
        '--query', '-q',
        type=str,
        default='–ö–∞–∫ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ä—Ç—É?',
        help='–ó–∞–ø—Ä–æ—Å –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞'
    )
    
    args = parser.parse_args()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    load_json_to_rag(args.file)
    
    # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç
    if args.test:
        test_search(args.query)

