# Настройка Ollama для бота

## Что такое Ollama?

Ollama - это инструмент для запуска больших языковых моделей (LLM) локально на вашем компьютере. Это полностью бесплатно и не требует интернета после установки.

## Преимущества

- ✅ **Полностью бесплатно** - нет лимитов и платы
- ✅ **Работает офлайн** - не нужен интернет после установки
- ✅ **Приватность** - все данные остаются на вашем компьютере
- ✅ **Нет лимитов** - используйте сколько угодно

## Требования

- **RAM:** минимум 8GB (рекомендуется 16GB+)
- **Диск:** 2-7GB свободного места (в зависимости от модели)
- **Процессор:** любой современный (GPU опционально, но ускоряет работу)

## Установка Ollama

### Windows

1. Скачайте установщик: https://ollama.ai/download
2. Запустите `ollama-windows-amd64.exe`
3. Следуйте инструкциям установщика
4. Ollama автоматически запустится после установки

### Проверка установки

Откройте PowerShell и выполните:
```powershell
ollama --version
```

Должна отобразиться версия, например: `ollama version is 0.1.x`

## Скачивание модели

### Рекомендуемые модели

#### 1. Mistral (Рекомендуется) ⭐
```powershell
ollama pull mistral
```
- **Размер:** ~4GB
- **Качество:** Отличное
- **Скорость:** Быстрая
- **RAM:** ~8GB

#### 2. Llama 2
```powershell
ollama pull llama2
```
- **Размер:** ~4GB
- **Качество:** Хорошее
- **Скорость:** Средняя
- **RAM:** ~8GB

#### 3. Phi-2 (Самый легкий)
```powershell
ollama pull phi
```
- **Размер:** ~2GB
- **Качество:** Хорошее для простых задач
- **Скорость:** Очень быстрая
- **RAM:** ~4GB (минимум)

#### 4. Llama 2 13B (Лучшее качество)
```powershell
ollama pull llama2:13b
```
- **Размер:** ~7GB
- **Качество:** Отличное
- **Скорость:** Медленная
- **RAM:** ~16GB+

### Проверка установленных моделей

```powershell
ollama list
```

## Настройка бота

### Шаг 1: Убедитесь, что Ollama запущен

Ollama должен работать в фоне. Проверьте:
```powershell
ollama list
```

Если команда работает - Ollama запущен.

### Шаг 2: Обновите .env файл

Откройте `.env` и добавьте/измените:

```env
# Использовать Ollama вместо OpenAI
LLM_PROVIDER=ollama

# Модель Ollama (по умолчанию: mistral)
OLLAMA_MODEL=mistral

# URL Ollama (по умолчанию: http://localhost:11434)
# OLLAMA_BASE_URL=http://localhost:11434
```

**Пример .env:**
```env
TELEGRAM_BOT_TOKEN=your_token_here
OPENAI_API_KEY=not_needed_for_ollama

# Настройки Ollama
LLM_PROVIDER=ollama
OLLAMA_MODEL=mistral
```

### Шаг 3: Перезапустите бота

```powershell
.\stop_bot.ps1
.\start_bot.ps1
```

## Проверка работы

При запуске бота вы должны увидеть:
```
[INFO] Используется Ollama с моделью: mistral
[INFO] Classifier использует Ollama с моделью: mistral
```

## Тестирование модели

Проверьте, что модель работает:

```powershell
ollama run mistral "Привет! Как дела?"
```

Модель должна ответить на русском языке.

## Решение проблем

### Ошибка: "Connection refused" или "Failed to connect"

**Причина:** Ollama не запущен

**Решение:**
1. Запустите Ollama вручную (должен быть в автозагрузке)
2. Или запустите вручную:
   ```powershell
   # Найдите и запустите Ollama
   # Обычно: C:\Users\YourName\AppData\Local\Programs\Ollama\ollama.exe
   ```

### Ошибка: "Model not found"

**Причина:** Модель не скачана

**Решение:**
```powershell
ollama pull mistral
```

### Медленная работа

**Решения:**
1. Используйте более легкую модель (phi вместо mistral)
2. Закройте другие программы
3. Увеличьте RAM (если возможно)
4. Используйте GPU (если доступен)

### Модель не отвечает на русском

**Решение:**
1. Убедитесь, что используете модель с поддержкой русского (mistral, llama2)
2. В промпте явно указывайте "Ответ на русском языке"

## Переключение между моделями

Чтобы использовать другую модель, просто измените в `.env`:

```env
OLLAMA_MODEL=phi  # Для более легкой модели
# или
OLLAMA_MODEL=llama2:13b  # Для лучшего качества
```

И перезапустите бота.

## Использование GPU (опционально)

Если у вас есть NVIDIA GPU, Ollama автоматически использует его для ускорения.

Проверка:
```powershell
ollama run mistral "test"
# Если использует GPU, будет быстрее
```

## Сравнение моделей

| Модель | Размер | Качество | Скорость | RAM |
|--------|--------|----------|----------|-----|
| **phi** | 2GB | ⭐⭐⭐ | ⚡⚡⚡ | 4GB |
| **mistral** | 4GB | ⭐⭐⭐⭐ | ⚡⚡ | 8GB |
| **llama2** | 4GB | ⭐⭐⭐⭐ | ⚡⚡ | 8GB |
| **llama2:13b** | 7GB | ⭐⭐⭐⭐⭐ | ⚡ | 16GB |

## Возврат к OpenAI

Если хотите вернуться к OpenAI, просто измените в `.env`:

```env
LLM_PROVIDER=openai
```

Или удалите строку `LLM_PROVIDER` (по умолчанию будет OpenAI).

## Полезные команды

```powershell
# Список моделей
ollama list

# Запуск модели для теста
ollama run mistral "Ваш вопрос"

# Удаление модели
ollama rm mistral

# Просмотр информации о модели
ollama show mistral
```

## Дополнительная информация

- Официальный сайт: https://ollama.ai
- Документация: https://github.com/ollama/ollama
- Список моделей: https://ollama.ai/library

